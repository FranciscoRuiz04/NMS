{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmlparser as parser\n",
    "import monthly\n",
    "from geopandas import read_file\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's parse the *kml* file which has the URLs to the statistics HTML file. For that is neccessary to pass a `pd.Series` type object with the respective station points into `seekData()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmlFile = r'EstacionesClimatologicas\\doc.kml'\n",
    "pointsFile = r'EstacionesClimatologicas\\ROI.gpkg'\n",
    "\n",
    "vectorPoints = read_file(pointsFile, layer='stats')\n",
    "stats = vectorPoints.Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to scrape the _**xml**_ content from _**kml**_ file to get the URL that will take us to statistics HTML file for the desired period passed. Once the link has been recovered, a new folder created by default into the current working directory named **RawData** will contain one __txt__ file for each station. There will exists the same data than we could find in the **National Meteorological Service**  official web page.\n",
    "\n",
    "If you want to change the root and folder name container, just pass `directory` argument into the parser with the desired path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.seekData(kmlFile, vectorPoints['Name'], 'MENSUALES', directory='RD_ProcessChunk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a **shelve** file with the raw data sorted by topic; that is, the kind of meteorological variable (e.g. Maximum Temperature, Averaged Precipitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly.createDB('RD_ProcessChunk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determinate year range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-structured data by topic of interest. `loadData()` function provides all the valid variable values for its `variable` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmax24: 9736 records\n",
      "p: 9736 records\n",
      "evo: 6611 records\n",
      "tmax_x: 9400 records\n",
      "tmax_mean: 9400 records\n",
      "tmin_x: 9398 records\n",
      "tmin_mean: 9398 records\n",
      "t: 9393 records\n"
     ]
    }
   ],
   "source": [
    "for var in monthly.__topics__:\n",
    "    df = monthly.loadData(var)\n",
    "    print(\"%s: %i records\" % (var, df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = monthly.loadData('p')\n",
    "\n",
    "\n",
    "y_label = p.stat.unique()\n",
    "x_label = range(p.year.min(), p.year.max() + 1)\n",
    "data = pd.DataFrame({'year': p.year, 'stat':p.stat})\n",
    "\n",
    "mx, mn = y_label.max(), y_label.min()\n",
    "class1 = data.query('@mn <= stat < 12000')\n",
    "class2 = data.query('%i < stat < 16000' % class1.stat.max())\n",
    "class3 = data.query('%i < stat < 18000' % class2.stat.max())\n",
    "class4 = data.query('%i < stat < 24000' % class3.stat.max())\n",
    "class5 = data.query('%i < stat <= @mx' % class4.stat.max())\n",
    "\n",
    "plots = class1, class2, class3, class4, class5\n",
    "sb.set_style('darkgrid')\n",
    "fig, axs = plt.subplots(nrows=5, tight_layout=True)\n",
    "fig.set_size_inches(15, 50, True)\n",
    "for i,plot in enumerate(plots):\n",
    "    stats = plot.stat.unique()\n",
    "    for stat in stats:\n",
    "        filtered = plot[plot.stat == stat]\n",
    "        if not filtered.empty:\n",
    "            axs[i].scatter(filtered.year, filtered.stat)\n",
    "    axs[i].set_ylim(ymin=stats.min(), ymax=stats.max())\n",
    "    axs[i].set_xlim(xmin=1980, xmax=2023)\n",
    "    axs[i].set_xlabel('Año')\n",
    "    axs[i].set_ylabel('Estación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the graphs the mayor amount of stations with at least one available record falls within **1980** to **2020**. Therefore, let's now filter the stations considering a tolerance for missing records (MR) per station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering with a tolerance of **5% MR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = monthly.loadData('p')\n",
    "t = monthly.loadData('t')\n",
    "tmin = monthly.loadData('tmin_mean')\n",
    "tmax = monthly.loadData('tmax_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, select records between 1980 and 2020 for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = p.query('1980 <= year <= 2020')\n",
    "t5 = t.query('1980 <= year <= 2020')\n",
    "tmin5 = tmin.query('1980 <= year <= 2020')\n",
    "tmax5 = tmax.query('1980 <= year <= 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select stations in common for all the varibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 stations in common\n"
     ]
    }
   ],
   "source": [
    "common_stats = set(p5.stat.unique()).intersection(t5.stat.unique()).intersection(tmin5.stat.unique()).intersection(tmax5.stat.unique())\n",
    "\n",
    "p_filtered = p5[p5.stat.isin(common_stats)]\n",
    "t_filtered = t5[t5.stat.isin(common_stats)]\n",
    "tmin_filtered = tmin5[tmin5.stat.isin(common_stats)]\n",
    "tmax_filtered = tmax5[tmax5.stat.isin(common_stats)]\n",
    "\n",
    "print(f\"{common_stats.__len__()} stations in common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11002</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11003</th>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11004</th>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11005</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24078</th>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24100</th>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24101</th>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24128</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24163</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       months_amount\n",
       "stat                \n",
       "11001            491\n",
       "11002            492\n",
       "11003            491\n",
       "11004            462\n",
       "11005            479\n",
       "...              ...\n",
       "24078            385\n",
       "24100            402\n",
       "24101            427\n",
       "24128            117\n",
       "24163            364\n",
       "\n",
       "[198 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_per_stat = p_filtered[['stat', 'months_amount']].groupby('stat').sum()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
